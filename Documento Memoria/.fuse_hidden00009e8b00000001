%% inicio, la clase del documento es iccmemoria.cls
\documentclass{iccmemoria}

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

%% datos generales y para la tapa
\titulo{Evasión de obstáculos con flujo óptico y redes neuronales para vehículos no tripulados}
\author{Jorge Gómez Valderrama}
\supervisor{Matthew Bardeen}
\informantes
	{Profesor Informante 1}
	{Profesor Informante 2}
\adicional{(sólo por si se necesita agregar algún otro profesor)}
\director{Profesor del ramo Memoria de Título}
\date{mes, año}

%% inicio de documento
\usepackage{graphicx}
\begin{document}

%% crea la tapa
\maketitle

%% dedicatoria
\begin{dedicatory}
Dedicado a ...
\end{dedicatory}

%% agradecimientos
\begin{acknowledgment}
Agradecimientos a ...
\end{acknowledgment}

%% indices
\tableofcontents
\listoffigures
\listoftables

%% resumen
\begin{resumen}
Aquí va el resumen (en Castellano)... 
\end{resumen}

%% abstract

%% contenido del primer capítulo
\chapter{Introducción}

\section{Descripción del contexto}

\section{Objetivos}

\subsection{Objetivo general}

\subsection{Objetivos específicos}

\section{Alcances}


%% contenido del segundo capítulo
\chapter{Marco teórico}

\section{Vehículo aéreo no tripulado}

Un vehículo aéreo no tripulado, UAV (por sus siglas del inglés: \emph{unmanned aerial vehicle}) o dron, es cualquier aeronave que no cuente con un piloto o tripulación a bordo, por lo que ésta puede volar de forma autónoma por medio de un computador a bordo o ser controlada remotamente por un humano \cite{icao2011UAS}.\\

Dentro de los vehículos aéreos no tripulados se encuentran los multirrotores o multicópteros, estas son aeronaves que generan sustentación por medio del giro de alas o hélices sobre un eje, siendo este conjunto llamado rotor. La Organización de Aviación Civil Internacional (CIAO por sus siglas del inglés: \emph{International Civil Aviation Organization}) los define como aeronaves que se mantienen en vuelo por las reacción del aire en uno o más rotores. En el caso de los multirrotores estos están compuestos por dos o más rotores, se diferencian de los helicópteros en la forma que logran el control y la estabilidad, estos tienen mecanismos que varían el paso de las hélices modificando su ángulo de ataque, en cambio los multirotores lo hacen por medio del cambio de velocidad relativa de cada rotor, produciendo cambios en el empuje y torque.\\

Un tipo de mutirrotor son los cuadricópteros los cuales tiene dos pares de rotores con hélices iguales y paso fijo, dos giran en sentido horario y los otros dos en sentido antihorario, esta configuración permite que el torque de cada rotor se anule con el rotor correspondiente que gira en sentido contrario, de esta forma el cuadricóptero se estabiliza y no gira sobre su propio eje \cite{AllenQuadcopters}.\\

Como se mencionó anteriormente los movimientos de los multirrotores se logran variando la velocidad de cada rotor independientemente, referencia a la imagen, con esto el quadricóptero puede moverse sobre 3 ejes perpendiculares, por medio de los movimientos de \emph{pitch}, \emph{roll} y \emph{yaw}, además de desplazarse por el eje $Z$ variando su altitud.\\

Con el movimiento \emph{pitch} el cuadricóptero rota sobre el eje $X$ y se desplaza hacia adelante o atrás por el eje $Y$, cuando ejecuta el movimiento de \emph{roll} rota sobre el eje Y y se desplaza de izquierda a derecha sobre el eje $X$ y gira sobre el eje $Z$ con el movimiento de \emph{yaw}. Con esto se logra tener control sobre 4 grados de libertad.\\



\section{Mecanismos de percepción}

\section{Software}

\subsection{OpenCV}

\emph{OpenCV} (Open Source Computer Vision Library) es una librería open source (código abierto) de \emph{computer visión}(visión por computador), distribuida bajo la licencia BSD, la cual está escrita en C y C++, siendo además multiplataforma. También existen interfaces para Python, Ruby, Matlab y otros lenguajes.\\

OpenCV está diseñado para ser eficiente computacionalmente y enfocado en ser utilizado en aplicaciones de procesamiento en tiempo real. Para esto, fue escrito en C optimizado y toma ventaja de los procesadores multi núcleo.\\

El proyecto fue iniciado por \emph{Intel Research Lablets} en 1990 con el propósito de hacer la infraestructura de la visión por computador universalmente disponible y de esta forma ampliar a su vez OpenCV fue pasado a código abierto \cite{bradski2008learning}.\\

\subsection{Visión por Computador}

\emph{Computer Vision} (visión por computador) es una disciplina que busca que los computadores puedan tener una comprensión de alto nivel sobre imágenes o videos digitales, por ejemplo, con el objetivo de automatizar tareas que el sistema visual humano ya puede hacer\cite{ballard1982computer, vandoni1996proceedings, sonka2008image}.\\

Dentro de las tareas de la visión por computador están: la adquisición, procesamiento, análisis, el entendimiento de imágenes digitales y la extracción de información multi dimensional del mundo real, para producir información numérica o simbólica \cite{klette2014concise, shapiro2001computer, morris2004computer, forsyth2003computer}.\\

Dado que nosotros percibimos el mundo principalmente por medio de la vista, parecería sencillo traspasar nuestra experiencia a la visión por computador, pero en realidad es una tarea muy difícil, debido a la complejidad de cómo funciona nuestro cerebro, contamos con múltiples sistemas que reciben distinta información segmentada desde el sistema visual e incluso otros sistemas, pero en el caso de la visión por computación solo contamos con una imagen (en el caso de video una secuencia de imágenes) y esto es todo lo el computador puede \emph{"ver"}.\\

Cuando hablamos de una imagen nos estamos refiriendo a la información que nos es capaz de entregar la luz que es recibida desde el entorno o una escena, esta información varia dependiendo del contexto en que se hable, si nos referimos a un marco biológico la luz incidirá en un ojo y las células en la retina generaran las señales eléctricas que el cerebro interpretará como imágenes, si hablamos de una cámara la imagen se formará en una película fogatica o en un sensor digital \cite{bradski2008learning}.\\

Dado el ámbito de este documento, es preciso profundizar en las imágenes digitales, esta puede ser definida como la integración y muestreo de información analógica (luz incidiendo en un sensor fotográfico) en un dominio espacial. Esta consiste en un arreglo rectangular de pixeles $(x, y, u)$, cada uno contiene una ubicación $(x, y) \in \mathbb{Z}^2 $ y un valor $u$, muestreado en una ubicación $(x, y)$. $\in$ es conjunto de puntos $(x, y)$ del arreglo rectangular \cite{klette2014concise}. Entonces podemos definir una imagen como:\\

\begin{equation}
	\begin{split}
	I = \lbrace (x, y) : 1 \leq  x \leq N_{cols} \wedge 1 \leq y \leq N_{rows} \rbrace \subset \mathbb{Z}^2
	\end{split}
\end{equation}

\subsection{OpenNN}

\subsection{Flujo óptico}

El flujo óptico es definido como el cambio de la estructura de la luz en una imagen, por ejemplo, en la retina de un ojo o en el sensor de una cámara, debido a movimiento relativo del observador y escena. Cuando los objetos se mueven frente a una cámara o esta se mueve en un entorno fijo, existe un cambio correspondiente a los movimientos en la imagen, estos cambios pueden utilizarse para recuperar información relativa al movimiento de las formas y los objetos.\\

Podemos definir un campo de movimiento, en el cual asignamos un vector de velocidad a cada punto de la imagen. En un instante en particular, un punto $P_i$ en la imagen corresponde con algún punto $P_0$ en la superficie de un objeto. Los dos puntos son conectados por la ecuación de proyección. Si consideramos una protección de perspectiva, una línea se extiende de un punto en la imagen, pasa por el centro de la lente (en el caso de tratarse de una cámara), hasta un punto en la superficie de la escena.\\


\begin{figure}[H]
  \centering
  \includesvg[width = 300pt, svgpath = images/proyeccion_flujo_optico]{}
  \caption{Proyección de un punto $P_0$ con movimoento $v_0$ en la escena  a un punto $P_i$ con movimiento $v_i$ sobre la imagen.}
  \label{fig:proyeccion_flujo_optico}
\end{figure}

El punto $P_{0}$ tiene una velocidad $v_{0}$ relativa a la cámara, esto induce un movimiento $v_{i}$ en el punto $P_{i}$ correspondiente en la imagen, como se puede ver en la figura \ref{fig:proyeccion_flujo_optico}\cite{horn1986robot}.\\

Los vectores de velocidad producidos por el movimiento aparente son descritos de forma distinta, dependiendo del contexto en que se presenten, de un punto de vista biológico los cambios estructurados en los patrones de la luz en la retina de un ojo dejan la impresión de movimiento, en visión por computación los cambios en la escena son representados por serie de \emph{image frames} (cuadros de imagen), la figura \ref{fig:ejemplo_flujo_optico} muestra una secuencia de tres cuadros, mediante un muestreo espacial y temporal de la luz incidente en la imagen, es decir, como se desplazan los pixeles en la imagen a través del tiempo.\\

\begin{figure}[H]
  \centering
  \includesvg[width = 300pt, svgpath = images/ejemplo_flujo_optico]{}
  \caption{Ejemplo de captura del flujo optico, por medio de cuandos de imagen consecutivos.}
  \label{fig:ejemplo_flujo_optico}
\end{figure}

Para calcular el flujo óptico por medio el análisis de imágenes se utiliza el método de \emph{Lucas-Kanade}, el cual funciona bajo dos suposiciones: la intensidad de un pixel en un determinado objeto no cambia entre cuadros consecutivos, refiriéndose a que un objeto no cambia en la escena, siempre la imagen proyectada de éste en la cámara es la misma. La segunda suposición dice que los vecinos cercanos a un pixel tiene un movimiento similar a este, esto permite evaluar una zona en la imagen.\\

Consideramos un pixel $I(x, y,t)$ en la primera imagen ($x$ e $y$ coordenadas dentro de la imagen y $t$ un instante de tiempo) el cual se mueve una distancia de $(dx, dy)$ en el siguiente cuadro después de un instante de tiempo $dt$, bajo las suposiciones mencionadas, podemos decir que:
\begin{equation}
	\begin{split}
		I(x,y,t) = I(x+dx, y+dy, t+dt)
	\end{split}
\end{equation}

Usando series de taylor aproximamos el lado derecho de la ecuación, removiendo términos semejantes y dividendo por dt obtenemos:
\begin{equation}
	\begin{split}
		f_x u + f_y v + f_t = 0
	\end{split}
\end{equation}

donde:
\begin{equation}
	\begin{split}
		f_x = \frac{\partial f}{\partial x} \; ; \; f_y = \frac{\partial f}{\partial y}
	\end{split}
\end{equation}

Esta es la ecuación del flujo óptico, donde $f_x$ y $f_y$ son gradientes de la imagen, como ft es gradiente del tiempo. Pero $(u, v)$ son desconocidas, por lo que no podemos resolver la ecuación con dos incognitas. Aquí es donde el método \emph{Lucas-Kanade} toma grupos de pixeles de 3x3, considerando las suposiciones mencionadas anteriormente, donde estos tiene el mismo movimiento. Ahora es posible resolver $(f_x, f_y, f_t)$ ya que contamos con nueve ecuaciones y las mismas dos incógnitas, resultando con la siguiente ecuación:
\begin{equation}
	\begin{split}
		\begin{bmatrix} u \\ v \end{bmatrix} = \begin{bmatrix} \sum_{i}{f_{x_i}}^2 & \sum_{i}{f_{x_i} f_{y_i} } \\ \sum_{i}{f_{x_i} f_{y_i}} & \sum_{i}{f_{y_i}}^2 \end{bmatrix}^{-1} \begin{bmatrix} - \sum_{i}{f_{x_i} f_{t_i}} \\ - \sum_{i}{f_{y_i} f_{t_i}} \end{bmatrix}
	\end{split}
\end{equation}

De esta forma se toma un grupo de pixeles y calculamos el flujo óptico sobre ellos, pero el método descrito funciona solo con pequeños movimientos, fallando en condiciones cunado los pixeles en la imagen sufren grandes movimientos, para solucionar este problema utilizamos el algoritmo de pyramid, el cual escala la imagen removiendo los pequeños movimientos y reduciendo los grandes movimientos a pequeños \cite{OpenCV}.\\

El algoritmo de \emph{pyrmid} se encarga de realizar \emph{downsampled}, este término se refiere a reducir la tasa de muestreo de alguna señal, a una imagen sucesivamente hasta algún límite dado, creando una colección de imágenes llamada pirámide. Existen dos tipos variantes del algoritmo de \emph{pyramid}: la gaussiana y la laplaciana, en el método de \emph{Lucas-Kanade} se utiliza la variante gaussiana, por lo que esta será descrita en detalle.\\

Para agregar a la pirámide una nueva capa $G_{i+1}$, debemos aplicar a la capa $G_i$ un filtro gaussiano y luego eliminar las columnas y filas pares, esto nos genera una nueva imagen con un cuarto del área de la imagen en la capa $G_i$, iterando este proceso desde la imagen original $G_0$ producimos la pirámide entera \cite{bradski2008learning}.\\

Cuando se realiza un proceso de muestreo en una señal, en este caso de una imagen, puede producirse \emph{alising}, el cual consiste en la distorsión de la señal orinal una vez que esta es muestreada, para evitar esto el teorema de muestreo \emph{Nyquist-Shannon} dice que es necesario muestrear una señal al doble de su frecuencia \cite{ImagePyramid}.\\

Es por esta razón que \emph{pyramid} aplica un filtro gaussiano para la capa $G_i$ de la pirámide antes de producir la capa $G_{i+1}$, esto reduce la frecuencia de la imagen en la capa $G_i$ dando como resultado una imagen con menor distorsión en la capa $G_{i+1}$, permitiendo tener una imagen de menor tamaño en una capa $G_j$, al final de la iteración, la cual tiene una baja distorsión frente a la imagen original en la capa $G_0$.\\

\subsection{Redes neuronales}

Una red neuronal tiene la finalidad de ser un modelo de una red neuronal biológica, que recibe un número determinado de entradas, las cuales son procesadas dentro de la red y producen una o más salidas. Una red neuronal biológica está conformada por la interconexión de neuronas, las cuales son células nerviosas que reciben estímulos y conducen el impulso nervioso, por medio de un potencial de acción, a otras neuronas \cite{cayre2002common}. De la misma forma una red neuronal está formada por neuronas, a las que nos referimos por ahora como perceptrón, este funciona tomando varias entradas $ x_{1}, x_{2}, $ \dots, para producir una sola salida binaria, como se muestra en la figura \ref{fig:perceptron}.\\

\begin{figure}[H]
  \centering
  \begin{Large}
  \includesvg[width = 300pt, svgpath = images/perceptron]{}
  \end{Large}
  \caption{Perceptrón con tres entradas: $x_{1}$, $x_{2}$ y $x_{3}$ que generea un salida binaria, con valor 0 o 1.}
  \label{fig:perceptron}
\end{figure}

En este caso se utilizan tres entradas, para computar la salida se introducen \emph{weights} (pesos) $w1, w2, w3$, números reales que representan la importancia de cada entrada con respecto a la salida. Finalmente, la salida de la neurona es calculada como la sumatoria $ \sum_{j}{} w_{j} x_{j}$, la salida binaria es 1 o 0 dependiendo de si el resultado de la sumatoria es menor o mayor al \emph{threshold value} (valor de activación), el cual es un número real, parámetro de la neurona.\\

\begin{equation}
	\begin{split}
	\mbox{salida} & = \begin{cases}
		0 & \mbox{si } \sum_j w_j x_j \leq  \mbox{ activación}\\
		1 & \mbox{si } \sum_j w_j x_j <  \mbox{ activación}
		\end{cases}
	\end{split}
\end{equation}\\


La red neuronal es conformada por la interconexión de perceptrones, los que se agrupan en \emph{layers} (capas), de tal modo que las salidas de los perceptrones en la primera capa son a su vez las entradas para los perceptrones de las segunda capa, así sucesivamente por la totalidad de las capas que constituyan la red neuronal.\\

\begin{figure}[H]
  \centering
  \begin{large}
  \includesvg[width = 400pt, svgpath = images/network]{}
  \end{large}
  \caption{Red neuronal conformada por 3 capas, la primera con 3 perceptrones, la segunda con 4 y la tercera y ultima con 1 perceptron.}
  \label{fig:red neuronal}
\end{figure}

En la definición de perceptrón se menciona que este solo cuenta con una salida, en la figura \ref{fig:red neuronal} se muestra que un perceptrón tiene múltiples salidas, pero de hecho es la misma única salida que se comparte cómo entrada para los perceptrones de la siguiente capa.\\

A la hora de implementar la red neuronal es posible realizar algunas simplificaciones, redefiniendo el comportamiento de los perceptrones, podemos suponer que las entradas y los pesos de estos están definidos como dos vectores, con lo que ahora para producir la salida se calcula el producto punto entre la entrada y los pesos, $ w \cdot x \equiv \sum_{j}{} w_{j} x_{j} $, también se mueve el valor de activación al otro lado de la inecuación y remplazándolo por el termino de \emph{bias} (sesgo del perceptrón), $ b \equiv -activaci\acute{o}n$, ahora el comportamiento del perceptrón se define como:\\

\begin{equation}
	\begin{split}
		\mbox{salida} = \begin{cases}
			0 & \mbox{si } w\cdot x + b \leq 0 \\
      		1 & \mbox{si } w\cdot x + b > 0
		\end{cases}
	\end{split}
\end{equation}\\

El sesgo puede definirse cómo que tan fácil el perceptrón puede producir una salida de valor 1, mientras más grande el sesgo más fácil producir una salida que sea 1.\\

Una de las principales características de las redes neuronales es su capacidad de aprender, para lograr esto la red debe variar tanto el valor de los pesos tanto como de los sesgos, para que de esta forma podamos tener la salida esperada a partir de una entrada determinada.\\

Para lograr este entrenamiento pequeños cambios en los parámetros de la red, pesos y sesgos, deben a su vez generar pequeños cambios en la salida, pero esto no sucede en las redes conformadas por perceptrones, caundo se aplica un pequeño cambio en los parámetros de un perceptrón produce que este cambie completamente su salida de 0 a 1, por ejemplo \cite{neuralNet}.\\

Este problema se soluciona remplazando los perceptrones por \emph{sigmoid neuron} (neurona sigmoide), en este tipo de neurona se pueden aplicar pequeños cambios en sus parámetros y esos se verán reflejados también en pequeños cambios en la salida. Una neurona sigmoide funciona de forma similar a un perceptrón donde la salida es calculada por $ \sigma(w \cdot x + b)$, $\sigma$ es una función sigmoide, definida cómo:\\

\begin{equation}
	\sigma(z) \equiv \frac{1}{1+e^{-z}}
\end{equation}\\

Remplazando el parámetro de la función por los de la neurona:\\

\begin{equation} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
\end{equation}\\


Al ser sigma una función continua, ahora la salida de la red no es binaria, si no que valor real entre 0 y 1, como se muestra en al figura \ref{fig:sigmoid}.\\

\begin{figure}[H]
  \centering
  \begin{small}
  \includesvg[width = 400pt, svgpath = images/sigmoid]{}
  \end{small}
  \caption{Función que utiliza una neurona sigmoide, como se puede ver la salida de la neurona sera un valor continuo, entre 0 y 1.}
  \label{fig:sigmoid}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{small}
  \includesvg[width = 400pt, svgpath = images/step]{}
  \end{small}
  \caption{Función escalonada que utilza un perceptron, el que tiene una salida binaria, con valores entre 0 y 1.}
  \label{fig:step}
\end{figure}

Ya se mencionó anteriormente que la forma en que la red neuronal aprende es ajustando los valores de los pesos y sesgos de las neuronas que la conforman, para conseguir este objetivo se utiliza el algoritmo de \emph{backpropagation}, primero se le entrega un vector de entrada a la red neuronal, se conoce de antemano la salida esperada que debe generar la red con estos valores, la red computa la salida y esta se compara con la salida esperada con algún método de optimización, en este caso se utiliza el descenso por gradiente.\\

El método de descenso por gradiente es un mecanismo de minimización, lo que busca minimizar es la función de error cuadrático medio entre la salida esperada y la salida que produce la red neuronal, una vez que se obtiene el gradiente del error este es propagado hacia atrás por la red modificando los pesos y los sesgos de las neuronas.

\section{Hardware}

\subsection{Robot omnidireccional}

Un robot omnidireccional (referido en este documento inherentemente como robot o robot omnidireccional) es un robot que tiene la capacidad de moverse en cualquier dirección sin tener que rotar antes de moverse, esto es posible a las ruedas omnidireccionales con que está construido el robot, esta tiene la capacidad de moverse libremente en dos direcciones, pueden rodar como una rueda normal o lateralmente con las ruedas ubicadas perpendicularmente a lo largo de la circunferencia, como se muestra en la figura \ref{fig:image_omni_whell}.\\

\begin{figure}[H]
  \centering
  \includesvg[width = 200pt, svgpath = images/image_omni_whell]{}
  \caption{Direcciones en las cuales puede moverse una rueda omnidireccional.}
  \label{fig:image_omni_whell}
\end{figure}


Esto permite que el robot puede trazar un camino en línea recta, en cualquier dirección, sin tener que hacer giros, además de poder combinar el trayecto con algún tipo de rotación para cambiar la dirección a la que apunta el robot, si es necesario, esto es definido como un robot holonómico, en comparación con un robot normal no-holonómico el cual tiene 1,5 grados de libertad que puede desplazarse a través de los ejes coordenados $X$ e $Y$, pero requiere movimientos complejos para poder moverse en el eje $X$. Un robot holonómico tiene 2 grados de libertad por lo que puede moverse libremente por ambos ejes $X$ e $Y$ \cite{jayakody2015omnirobot}.\\

Para lograr que el robot se desplace en cualquier dirección es necesario calcular la velocidad y dirección de giro para cada rueda de forma independiente, 


\subsubsection{Rueda omnidireccional}

\subsubsection{Motores reductores}

\subsubsection{Servo motores}

\subsubsection{Controlador para motores}

\subsection{Microcomputador}

\subsection{Microcontrolador}

\subsection{Camara}


%% contenido del tercer capítulo
\chapter{Implementación}

\section{Flujo óptico}

\subsection{Captura de flujo óptico}

\subsection{Procesado de flujo óptico}

\section{Red neuronal}

\subsection{Diseño de capas}

\subsection{Entrenamiento}

Para entrenar la red neuronal se utiliza como entrada el flujo óptico obtenido de la captura de video de la pista de pruebas y como salida esperada la dirección en la cual se mueve el robot [agregar marco de referencia]. Para modificar los pesos al interior de la red, que se traduce como el aprendizaje de la red, se utiliza la técnica de \emph{backpropagation}.\\

La generación de set de datos del cual la red aprende se hace por medio de un esquema [mejor traducción] \emph{on-the-fly}, el cual tiene como objetivo que la red neuronal imite el comportamiento de un humano al realizar la misma tarea, la que cual es desplazar el robot por la pista de pruebas. Por lo que el flujo óptico y la dirección del robot se obtiene de la conducción manual del robot.\\

La obtención del flujo óptico se hace desde la captura de video del recorrido del robot por la pista de pruebas. Ya que la respuesta de la red neuronal sobre el robot es refleja solo sobre un eje de movimiento, solo importa rescatar desde las imágenes del video la posición de la información de forma horizontal sin importar que tan arriba o abajo se encuentre dentro de la imagen, ya que sin importar la variación de este último parámetro la respuesta de red neuronal debería ser la misma.
Siguiendo con este tópico y los alcances de las pruebas, no se necesita la información del flujo óptico que se registre de forma vertical, solo tiene importancia para este caso el flujo que se registre en forma horizontal. Esto permite simplificar los datos obtenidos desde las imágenes reduciendo la dimensión de los vectores obtenidos, de dos dimensiones a solo una.\\

Otra consideración en la obtención del flujo óptico es sobre la pista de pruebas, la cual entregara una imagen que es monótona de forma vertical [mejor descripción?], es decir, si se analiza la imagen de forma vertical los datos que se obtendrán serán muy similares, lo que conlleva a poder reducir los datos que se necesitan obtener sin reducir la información que generaliza a toda la imagen, por lo que solo basta con tomar una franja horizontal de la imagen para tener la información necesaria para la entrada de la red neuronal.\\

Originalmente la representación del flujo óptico consta de un vector bidimensional por cada punto que se examine de la imagen, esta información se podría representar por dos vectores de dimensión n, donde n es la cantidad de puntos observados en la imagen, y un vector representaría la información del flujo óptico horizontal y otro vertical. Dada las consideraciones mencionadas anteriormente solo se necesita utilizar como vector de entrada para la red neuronal el que contenga la información del flujo óptico en el eje horizontal de la imagen, además la dimensionalidad de este se verá disminuida por la reducción de puntos a tomar en cuenta en la imagen.\\

La salida esperada de la red neuronal, que representa la dirección en la que se mueve el robot en forma horizontal y que será utilizada como parámetro para el entrenamiento por backpropagation, será obtenida por el seguimiento de los movimientos que realice el robot por medio de un sensor óptico de movimiento. La arquitectura de la red neuronal tendrá una sola salida la que estará normalizada [rango de la salida], por lo que la dirección del robot será representada por un solo valor.\\

Para lograr que la red neuronal aprenda se utiliza un entrenamiento del tipo \emph{on-the-fly}, el cual consiste en que la red logre imitar el comportamiento que tendría un humano al realizar la misma tarea, se debe entregar a la red un set de datos generados, en este caso, de la conducción manual del robot por la pista de pruebas, este set de datos consta del flujo óptico obtenido de la captura de video, que se utilizara como entrada de red neuronal, y de la dirección en la cual se movió el robot [agregar marco de referencia] \\

\section{Robot omnidireccional}

El diseño del robot está basado en uno del repositorio de diseños 3D thingiverse (https://www.thingiverse.com/thing:167923), de este se tomó el concepto de las ruedas omnidireccionales y se rediseñaron, la construcción consta de dos ruedas paralelas rotadas sobre el eje de giro 45$^{\circ}$ una de la otra, cada una de estas ruedas cuanta a su vez con cuatro ruedas o rodillos en su circunferencia colocadas perpendicularmente separadas cada una por 90$^{\circ}$, esto permite tener un solapamiento con los rodillos de la otra rueda ubicada perpendicular a esta, cada rueda tiene un diámetro de 80mm y un ancho de 40mm, en la imagen [referencia imagen] se puede ver la construcción de esta.\\

Cada una de las ruedas es accionada por un motor de corriente continua (DC) del estándar 130, con una caja reductora TT de 90$^{\circ}$, con una relación de 120:1, el modelo se muestra en la imagen [referencia]\\

A su vez los motores están unidos por una extensión que permite unirlos al cuerpo principal, de esta forma se puede modificar el diámetro total del robot sin tener que modificar también el cuerpo principal, [referencia imagen]
En el cuerpo principal se posicionan el resto de los componentes necesarios para el funcionamiento, estos son el microcontrolador, los \emph{driver} para los motores, las baterías, el receptor de radio, la cámara digital y sensor de movimiento. El cuerpo fue diseñado de acuerdo a las dimensiones de cada componente, de esta manera se pueden colocar de manera precisa, además de usar las fijaciones para las cuales fueron diseñados. [referencia imagen]
El compartimiento para las baterías es ubicado debajo de cuerpo principal, este permite la fijación de baterías de litio estándar 18650 colocadas en serie, permite colocar un total de 3 baterías, así se consigue un voltaje nominal de 11,1 V, que permite alimentar los directamente el microcontrolador y los drivers para los motores. [referencia imagen]\\

Los componentes mencionados y diseñados específicamente para el robot (ruedas omnidireccionales, extensiones para los motores, cuerpo principal y compartimiento para baterías) fueron construidos por medio de la impresión 3D, con las siguientes especificaciones:\\

\chapter{Pruebas}

Las pruebas que se realizan para comprobar si la red neuronal es capaz de evadir obstáculos se dividen en dos etapas: La primera consta en mover el robot sobre la pista de pruebas sin colocar obstáculos, solo con información visual a los costados, la que será captada como flujo óptico, esta permitirá que el robot evite los bordes de la pista y sea capaz de centrarse dentro de esta. En la segunda etapa se mantendrá el esquema de la primera, además de incluir un obstáculo en la pista de pruebas, que el robot tendrá que evadir.\\

Por cada una de las etapas se comprobará, de dos formas distintas, si la red neuronal está aprendiendo por medio del método de entrenamiento \emph{backpropagation}. La primera es evaluando el aprendizaje con un set de datos distinto al del entrenamiento, aquí se evalúa cuanto difiere la salida esperada con la que entrega la red. Esta diferencia se considera \emph{test error} (error de prueba) y esta será obtenida por la técnica de \emph{Validation Set Approach} (enfoque de conjunto de validación) la que consiste en dejar parte del conjunto de entrenamiento para validar cuan efectivo fue este.\\

[completar cuantos datos de entrenamiento fueron y cuantos se dejaron para validation set approach]
la implementación de la red reordena de forma aleatoria el conjunto de datos y desde este crea un conjunto de datos para las pruebas.\\

La cuantificación del error se realiza midiendo el porcentaje de efectividad de la red, contando la cantidad de veces que la salida de la red es una respuesta esperada, para saber si la salida satisface esta condición se establece un margen de aceptación de [porcentaje de aceptación], para qué se considere un entrenamiento efectivo la eficacia de la red debe estar sobre un [porcentaje de efectividad]\\ 

La segunda comprobación de entrenamiento se realizará de forma empírica, comparando el comportamiento de la conducción manual del robot, contra la conducción autónoma guiada por la red neuronal, cada vez que el robot se desplace por la pista de pruebas se deja registro de su desplazamiento, por lo que se puede comparar el recorrido realizado de forma manual y el de forma autónoma. Para considerar la prueba exitosa la desviación de las dos trayectorias no debe ser mayor a [medida de desviación].\\

La obtención del conjunto datos, para realizar las pruebas, consta de conducir de forma manual el robot repetidas veces por la pista de pruebas, colocando el robot en posiciones definidas al comienzo de la pista y dirigirlo hasta el final de esta.\\

Para la primera etapa, sin importar la posición de inicio, tiene como objetivo mover el robot al centro de la pista direccionándolo solo de forma horizontal [mejorar descripción del movimiento de robot, para que de esta forma la red neuronal pueda aprender a direccionar el robot evadiendo los bordes de la pista.\\

En la segunda etapa se posicionará un obstáculo dentro de la pista, al igual que en la primera etapa, también se deberá centrar el robot dentro de la pista, pero al enfrentarse a un obstáculo este debe ser evadido.\\

Para realizar la recopilación de datos, el inicio de la pista será dividido en [n] secciones iguales la que estarán divididas en [cm] una de otra, de donde comenzara el robot, por cada una de estas secciones se registrarán [n] recorridos del robot sobre la pista, obteniendo la información de flujo óptico y el recorrido echo por este. El recorrido registrado será a una velocidad constante [velocidad del robot] y recorrerá una distancia de [distancia a recorrer].\\

Para la recopilación de datos con obstáculos, se utilizará el mismo esquema anterior, pero se posicionará un obstáculo dentro de pista en distintas posiciones predefinas, estas posiciones son representadas dentro de la pista por una matriz, la cual será de [n] filas y [m] columnas, la separación entre las filas y las columnas será igual y de [cm], y estará posicionada en la pista a [distancia] del inicio de la pista y centrada con respecto a los bordes. Por cada obstáculo se recopilarán los datos [n] veces por cada posición de inicio de la pista.\\

La construcción de la pista de pruebas necesita de un material que proporcione tracción a las ruedas del robot, por lo que se utiliza una alfombra de cubre pisos de 1 metro de ancho y 4 metros de largo, de color beige para proporcionar mayor contraste frente a los obstáculos, los bordes de la pista tendrán un alto de [cm] con un patrón regular líneas verticales blancas y negras de [cm] de ancho.

\chapter{Resultados}




%% ambiente glosario
\begin{glosario}
  \item[El primer término:] Este es el significado del primer término, realmente no se bien lo que significa pero podría haberlo averiguado si hubiese tenido un poco mas de tiempo.
  \item[El segundo término:] Este si se lo que significa pero me da lata escribirlo...
\end{glosario}


%% genera las referencias
\bibliography{refs}


%% comienzo de la parte de anexos
\appendixpart

%% contenido del primer anexo
\appendix{El Primer Anexo}
Aquí va el texto del primer anexo...

\section{La primera sección del primer anexo}
Aquí va el texto de la primera sección del primer anexo...

\section{La segunda sección del primer anexo}
Aquí va el texto de la segunda sección del primer anexo...

\subsection{La primera subsección de la segunda sección del primer anexo}


%% contenido del segundo anexo
\appendix{El segundo Anexo}
Aquí va el texto del segundo anexo...

\section{La primera sección del segundo anexo}
Aquí va el texto de la primera sección del segundo anexo...

%% fin
\end{document}

   

