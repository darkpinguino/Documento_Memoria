%% inicio, la clase del documento es iccmemoria.cls
\documentclass{iccmemoria}

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

%% datos generales y para la tapa
\titulo{Evasión de obstáculos con flujo óptico y redes neuronales para vehículos no tripulados}
\author{Jorge Gómez Valderrama}
\supervisor{Matthew Bardeen}
\informantes
	{Profesor Informante 1}
	{Profesor Informante 2}
\adicional{(sólo por si se necesita agregar algún otro profesor)}
\director{Profesor del ramo Memoria de Título}
\date{mes, año}

%% inicio de documento
\begin{document}

%% crea la tapa
\maketitle

%% dedicatoria
\begin{dedicatory}
Dedicado a ...
\end{dedicatory}

%% agradecimientos
\begin{acknowledgment}
Agradecimientos a ...
\end{acknowledgment}

%% indices
\tableofcontents
\listoffigures
\listoftables

%% resumen
\begin{resumen}
Aquí va el resumen (en Castellano)... 
\end{resumen}

%% abstract

%% contenido del primer capítulo
\chapter{Introducción}

\section{Descripción del contexto}

\section{Objetivos}

\subsection{Objetivo general}

\subsection{Objetivos específicos}

\section{Alcances}


%% contenido del segundo capítulo
\chapter{Marco teórico}

\section{Drones}

\section{Mecanismos de percepción}

\section{Software}

\subsection{OpenCV}

\emph{OpenCV} (Open Source Computer Vision Library) es una librería open source (código abierto) de computer visión (visión por computador), distribuida bajo la licencia BSD, la cual está escrita en C y C++, siendo además multiplataforma. También existen interfaces para Python, Ruby, Matlab y otros lenguajes.\\

OpenCV está diseñado para ser eficiente computacionalmente y enfocado en ser utilizado en aplicación de procesamiento en tiempo real. Para esto, fue escrito en C optimizado y toma ventaja de los procesadores multi núcleo.\\

El proyecto fue iniciado por \emph{Intel Research Lablets} en 1990, pero con el propósito de hace la infraestructura de la visión por computador universalmente disponible y de esta forma ampliar a su ver OpenCV fue pasado a código abierto \cite[bradski2008learning].\\

\subsection{Visión por Computador}

Computer Vision es una disciplina que busca que los computadores puedan tener una comprensión de alto nivel sobre imágenes o videos digitales, por ejemplo, con el objetivo de automatizar tareas que sistema visual humano ya puede hacer[ballard1982computer][ vandoni1996proceedings][ Image processing, analysis, and machine vision].\\

Dentro de las tareas de la visión por computador están: la adquisición, procesamiento, análisis, el entendimiento de imágenes digitales y la extracción de información multi dimensional del mundo real, para producir información numérica o simbólica[klette2014concise][ shapiro2001computer][ morris2004computer][ forsyth2003computer].\\

Dado que nosotros percibimos el mundo principalmente por medio de la vista, parecería sencillo traspasar nuestra experiencia a la visión por computador, pero en realidad es una tarea muy difícil, debido a la complejidad de cómo funciona nuestro cerebro, contamos con múltiples sistemas que reciben distinta información segmentada desde el sistema visual e incluso otros sistemas, para la visión por computación solo contamos con una imagen (en el caso de video una secuencia de imágenes) y esto es todo lo el computador puede ver.\\

Cuando hablamos de una imagen nos estamos refiriendo a la información que nos es capaz de entregar la luz que es recibida desde el entorno o una escena, esta información varia dependiendo del contexto en que se hable, si nos referimos a un marco biológico la luz incidirá en un ojo y las células en la retina generaran las señales eléctricas que el cerebro interpretara como imágenes, si hablamos de una cámara la imagen se formara en una película fogatica o en un sensor digital[bradski2008learning].\\

Dado el ámbito de este documento, es preciso profundizar en las imágenes digitales, esta puede ser definida como la integración y muestreo de información analógica (luz incidiendo en un sensor fotográfico) en un dominio espacial. Esta consiste en un arreglo rectangular de pixeles $(x, y, u)$, cada uno contiene una ubicación $(x, y) \in \mathbb{Z}^2 $ y un valor $u$, muestreado en una ubicación $(x, y)$. $\in$ es conjunto de puntos $(x, y)$ del arreglo rectangular \cite{klette2014concise}. Entonces podemos definir una imagen como:\\

\begin{equation}
	\begin{split}
	I = \lbrace (x, y) : 1 \leq  x \leq N_{cols} \wedge 1 \leq y \leq N_{rows} \rbrace \subset \mathbb{Z}^2
	\end{split}
\end{equation}

\subsection{OpenNN}

\subsection{Flujo óptico}

El flujo óptico es definido como el cambio de la estructura de la luz en una imagen, por ejemplo, en la retina de un ojo o en el sensor de una cámara, debido a movimiento relativo del observador y escena. Cuando los objetos se mueven frente a una cámara o esta se mueve en un entorno fijo, existe un cambio correspondiente a los movimientos en la imagen, estos cambios pueden utilizarse para recuperar información relativa al movimiento de las formas y los objetos.\\

Podemos definir un campo de movimiento, en el cual asignamos un vector de velocidad a cada punto de la imagen. En un instante en particular, un punto $P_i$ en la imagen corresponde con algún punto $P_0$ en la superficie de un objeto. Los dos puntos son conectados por la ecuación de proyección. Si consideramos una protección de perspectiva, una línea se extiende de un punto en la imagen, pasa por el centro de la lente (en el caso de tratarse de una cámara), hasta un punto en la superficie de la escena.\\

imagen\\

El punto $P_{0}$ tiene una velocidad $v_{0}$ relativa a la cámara, esto índice un movimiento $v_{i}$ en el punto $p_{i}$ correspondiente en la imagen\cite{horn1986robot}.\\

Los vectores de velocidad producidos por el movimiento aparente son descritos de forma distinta, dependiendo del contexto en que se presenten, de un punto de vista biológico los cambios estructurados en los patrones de la luz en la retina de un ojo dejan la impresión de movimiento, en visión por computación los cambios en la escena son representados por serie de \emph{image frames} (cuados de imagen), la figura (imagen del monito) muestra una secuencia de tres cuadros, mediante un muestreo espacial y temporal de la luz incidente en la imagen, es decir, como se desplazan los pixeles en la imagen a través del tiempo.\\

imagen\\

Para calcular el flujo óptico por medio el análisis de imágenes se utiliza el método de \emph{Lucas-Kanade}, el cual funciona bajo dos suposiciones: la intensidad de un pixel en un determinado objeto no cambia entre cuadros consecutivos, refiriéndose a que un objeto no cambia en la escena, siempre la imagen proyectada de este en la cámara es la misma. La segunda suposición dice que los vecinos cercanos a un pixel tiene un movimiento similar a este, esto permite evaluar una zona en la imagen.\\

Consideramos un pixel $I(x, y,t)$ en la primera imagen ($x$ e $y$ coordenadas dentro de la imagen y $t$ un instante de tiempo) el cual se mueve una distancia de $(dx, dy)$ en el siguiente cuandro después de un instante de tiempo $dt$, bajo las suposiciones mencionadas, podemos decir que:
\begin{equation}
	\begin{split}
		I(x,y,t) = I(x+dx, y+dy, t+dt)
	\end{split}
\end{equation}

Usando series de taylor aproximamos el lado derecho de la ecuación, removiendo términos semejantes y dividendo por dt obtenemos:
\begin{equation}
	\begin{split}
		f_x u + f_y v + f_t = 0
	\end{split}
\end{equation}

donde:
\begin{equation}
	\begin{split}
		f_x = \frac{\partial f}{\partial x} \; ; \; f_y = \frac{\partial f}{\partial y}
	\end{split}
\end{equation}

Esta es la ecuación del flujo óptico, donde $f_x$ y $f_y$ son gradientes de la imagen, como ft es gradiente del tiempo. Pero $(u, v)$ son desconocidas, por lo que no podemos resolver la ecuación con dos incognitas. Aquí es donde el método \emph{Lucas-Kanade} toma grupos de pixeles de 3x3, considerando las suposiciones mencionadas anteriormente, donde estos tiene el mismo movimiento. Ahora es posible resolver $(f_x, f_y, f_t)$ ya que contamos con nueve ecuaciones y las mismas dos incógnitas, resultando con la siguiente ecuación:
\begin{equation}
	\begin{split}
		\begin{bmatrix} u \\ v \end{bmatrix} = \begin{bmatrix} \sum_{i}{f_{x_i}}^2 & \sum_{i}{f_{x_i} f_{y_i} } \\ \sum_{i}{f_{x_i} f_{y_i}} & \sum_{i}{f_{y_i}}^2 \end{bmatrix}^{-1} \begin{bmatrix} - \sum_{i}{f_{x_i} f_{t_i}} \\ - \sum_{i}{f_{y_i} f_{t_i}} \end{bmatrix}
	\end{split}
\end{equation}

De esta forma tomas un grupo de pixeles y calculamos el flujo óptico sobre ellos, pero el método descrito funciona solo con pequeños movimientos, fallando en condiciones cunado los pixeles en la imagen sufren grandes movimientos, para solucionar este problema utilizamos el algoritmo de pyramid, el cual escala la imagen removiendo los pequeños movimientos y reduciendo los grandes movimientos a pequeños \cite{OpenCV}.\\

El algoritmo de \emph{pyrmid} se encarga de realizar \emph{downsampled}, este término se refiere a reducir la tasa de muestreo de alguna señal, a una imagen sucesivamente hasta algún límite dado, creando una colección de imágenes llamada pirámide. Existen dos tipos variantes del algoritmo de \emph{pyramid}: la gaussiana y la laplaciana, en el método de \emph{Lucas-Kanade} se utiliza la variante gaussiana, por lo que esta será descrita en detalle.\\

Para agregar a la pirámide una nueva capa $G_{i+1}$, debemos aplicar a la capa $G_i$ un filtro gaussiano y luego eliminar las columnas y filas pares, esto nos genera una nueva imagen con un cuarto del área de la imagen en la capa $G_i$, iterando este proceso desde la imagen original $G_0$ producimos la pirámide entera \cite{bradski2008learning}.\\

Cuando se realiza un proceso de muestreo en una señal, en este caso de una imagen, puede producirse \emph{alising}, el cual consiste en la distorsión de la señal orinal una vez que esta es muestreada, para evitar esto el teorema de muestreo \emph{Nyquist-Shannon} dice que es necesario muestrear una señal al doble de su frecuencia \cite{ImagePyramid}.\\

Es por esta razón que \emph{pyramid} aplica un filtro gaussiano para la capa $G_i$ de la pirámide antes de producir la capa $G_{i+1}$, esto reduce la frecuencia de la imagen en la capa $G_i$ dando como resultado una imagen con menor distorsión en la capa $G_{i+1}$, permitiendo tener una imagen de menor tamaño en una capa $G_j$, al final de la iteración, la cual tiene una baja distorsión frente a la imagen original en la capa $G_0$.\\

\subsection{Redes neuronales}

Una red neuronal tiene la finalidad de ser un modelo de una red neuronal biológica, la cual recibe un número determinado de entradas, las cuales son procesadas dentro de la red y producen una o más salidas. Una red neuronal biológica está conformada por la interconexión de neuronas, las cuales son células nerviosas que reciben estímulos y conducen el impulso nervioso, por medio de un potencial de acción, a otras neuronas \cite{cayre2002common}. De la misma forma una red neuronal está formada por neuronas, a las que nos referimos por ahora como perceptrón, este funciona tomando varias entradas $ x1, x2, $ \dots, para producir una sola salida binaria.\\

En este caso se utilizan tres entradas, para computar la salida se introducen \emph{weights} (pesos) $w1, w2, w3$, números reales que representan la importancia de cada entrada con respecto a la salida. Finalmente, la salida de ls neurona es calculada como la sumatoria $ \sum_{j}{} w_{j} x_{j}$, la salida binaria es 1 o 0 dependiendo de si el resultado de la sumatoria es menor o mayor al \emph{threshold value} (valor de activación), el cual es un número real, parámetro de la neurona.\\

\begin{equation}
	\begin{split}
	\mbox{output} & = \begin{cases}
		0 & \mbox{if } \sum_j w_j x_j \leq  \mbox{ threshold}\\
		1 & \mbox{if } \sum_j w_j x_j <  \mbox{ threshold}
		\end{cases}
	\end{split}
\end{equation}\\


La red neuronal es conformada por la interconexión de perceptrones, los que se agrupan en \emph{layers} (capas), de tal modo que las salidas de los perceptrones en la primera capa son a su vez las entradas para los perceptrones de las segunda capa, así sucesivamente por la totalidad de las capas que constituyan la red neuronal.\\

En la definición de perceptrón se menciona que este solo cuenta con una salida, en la imagen se muestra que un perceptrón tiene múltiples salidas, pero de hecho es la misma única salida que se comparte cómo entrada para los perceptrones de la siguiente capa.\\

A la hora de implementar la red neuronal es posible realizar algunas simplificaciones, redefiniendo el comportamiento de los perceptrones, podemos suponer que las entradas y los pesos de estos están definidos como dos vectores, con lo que ahora para producir la salida se calcula el producto punto entre la entrada y los pesos, $ w \cdot x \equiv \sum_{j}{} w_{j} x_{j} $, también se mueve el valor de activación al otro lado de la inecuación y remplazándolo por el termino de \emph{bias} (sesgo del perceptrón), $ b \equiv -threshold$, ahora el comportamiento del perceptrón se define como:\\

\begin{equation}
	\begin{split}
		\mbox{output} = \begin{cases}
			0 & \mbox{if } w\cdot x + b \leq 0 \\
      		1 & \mbox{if } w\cdot x + b > 0
		\end{cases}
	\end{split}
\end{equation}\\

El sesgo puede definirse cómo que tan fácil el perceptrón puede producir una salida da valor 1, mientras más grande el sesgo más fácil producir una salida que sea 1.\\

Una de las principales características de las redes neuronales es su capacidad de aprender, para lograr esto la red debe variar tanto el valor de los pesos tanto como de los sesgos, para que de esta forma podamos tener la salida esperada a partir de una entrada determinada.\\

Para lograr este entrenamiento pequeños cambios en los parámetros de la red, pesos y sesgos, deben a su vez generar pequeños cambios en la salida, pero esto no sucede en las redes conformadas por perceptrones, aplicar un pequeño cambio en los parámetros de un perceptrón produce que este cambie completamente su salida de 0 a 1, por ejemplo \cite{neuralNet}.\\

Este problema se soluciona remplazando los perceptrones por sigmoid neuron (neurona sigmoide), en este tipo de neurona se pueden aplicar pequeños cambios en sus parámetros y esos se verán reflejados también en pequeños cambios en la salida. Una neurona sigmoide funciona de forma similar a un perceptrón donde la salida es calculada por $ \sigma(w \cdot x + b)$, $\sigma$ es una función sigmoide, definida cómo:\\

\begin{equation}
	\sigma(z) \equiv \frac{1}{1+e^{-z}}
\end{equation}\\

Remplazando el parámetro de la función por los de la neurona:\\

\begin{equation} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
\end{equation}\\


Al ser sigma una función continua, ahora la salida de la red no es binaria, si no que valor real entre 0 y 1.\\

Ya se mencionó anteriormente que la forma en que la red neuronal aprende es ajustando los valores de los pesos y sesgos de las neuronas que la conforman, para conseguir este objetivo se utiliza el algoritmo de \emph{backpropagation}, primero se le entrega un vector de entrada a la red neuronal, se conoce de antemano la salida esperada que debe generar la red con estos valores, la red computa la salida y esta se compara con la salida esperada con algún método de optimización, en este caso se utiliza el descenso por gradiente.\\

El método de descenso por gradiente es un mecanismo de minimización, lo que busca minimizar es la función de error cuadrático medio entre la salida esperada y la salida que produce la red neuronal, una vez que se obtiene el gradiente del error este es propagado hacia atrás por la red modificando los pesos y los sesgos de las neuronas.

\section{Hardware}

\subsection{Robot omnidireccional}

\subsubsection{Rueda omnidireccional}

\subsubsection{Motores reductores}

\subsubsection{Servo motores}

\subsubsection{Controlador para motores}

\subsection{Microcomputador}

\subsection{Microcontrolador}

\subsection{Camara}


%% contenido del tercer capítulo
\chapter{Implementación}

\section{Flujo óptico}

\subsection{Captura de flujo óptico}

\subsection{Procesado de flujo óptico}

\section{Red neuronal}

\subsection{Diseño de capas}

\subsection{Entrenamiento}

Para entrenar la red neuronal se utiliza como entrada el flujo óptico obtenido de la captura de video de la pista de pruebas y como salida esperada la dirección en la cual se mueve el robot [agregar marco de referencia]. Para modificar los pesos al interior de la red, que se traduce como el aprendizaje de la red, se utiliza la técnica de backpropagation.\\

La generación de set de datos del cual la red aprende se hace por medio de un esquema [mejor traducción] “on-the-fly”, el cual tiene como objetivo que la red neuronal imite el comportamiento de un humano al realizar la misma tarea, la que cual es desplazar el robot por la pista de pruebas. Por lo que el flujo óptico y la dirección del robot se obtiene de la conducción manual del robot.\\

La obtención del flujo óptico se hace desde la captura de video del recorrido del robot por la pista de pruebas. Ya que la respuesta de la red neuronal sobre el robot es refleja solo sobre un eje de movimiento, solo importa rescatar desde las imágenes del video la posición de la información de forma horizontal sin importar que tan arriba o abajo se encuentre dentro de la imagen, ya que sin importar la variación de este último parámetro la respuesta de red neuronal debería ser la misma.
Siguiendo con este tópico y los alcances de las pruebas, no se necesita la información del flujo óptico que se registre de forma vertical, solo tiene importancia para este caso el flujo que se registre en forma horizontal. Esto permite simplificar los datos obtenidos desde las imágenes reduciendo la dimensión de los vectores obtenidos, de dos dimensiones a solo una.\\

Otra consideración en la obtención del flujo óptico es sobre la pista de pruebas, la cual entregara una imagen que es monótona de forma vertical [mejor descripción?], es decir, si se analiza la imagen de forma vertical los datos que se obtendrán serán muy similares, lo que conlleva a poder reducir los datos que se necesitan obtener sin reducir la información que generaliza a toda la imagen, por lo que solo basta con tomar una franja horizontal de la imagen para tener la información necesaria para la entrada de la red neuronal.\\

Originalmente la representación del flujo óptico consta de un vector bidimensional por cada punto que se examine de la imagen, esta información se podría representar por dos vectores de dimensión n, donde n es la cantidad de puntos observados en la imagen, y un vector representaría la información del flujo óptico horizontal y otro vertical. Dada las consideraciones mencionadas anteriormente solo se necesita utilizar como vector de entrada para la red neuronal el que contenga la información del flujo óptico en el eje horizontal de la imagen, además la dimensionalidad de este se verá disminuida por la reducción de puntos a tomar en cuenta en la imagen.\\

La salida esperada de la red neuronal, que representa la dirección en la que se mueve el robot en forma horizontal y que será utilizada como parámetro para el entrenamiento por backpropagation, será obtenida por el seguimiento de los movimientos que realice el robot por medio de un sensor óptico de movimiento. La arquitectura de la red neuronal tendrá una sola salida la que estará normalizada [rango de la salida], por lo que la dirección del robot será representada por un solo valor.\\

Para lograr que la red neuronal aprenda se utiliza un entrenamiento del tipo “on-the-fly” , el cual consiste en que la red logre imitar el comportamiento que tendría un humano al realizar la misma tarea, esto se logra entregando a la red un set de datos generados, en este caso, de la conducción manual del robot por la pista de pruebas, este set de datos consta del flujo óptico obtenido de la captura de video, que se utilizara como entrada de red neuronal, y de la dirección en la cual se movió el robot [agregar marco de referencia] \\

\section{Robot omnidireccional}

\chapter{Pruebas}

Las pruebas que se realizan, para comprobar si la red neuronal es capaz evadir obstáculos, se dividen en dos etapas: La primera consta de mover el robot sobre la pista de pruebas sin colocar obstáculos, solo con información visual a los costados, la que será captada como flujo óptico, esta permitirá que el robot evite los bordes de la pista y sea capaz de centrarse dentro de esta. En la segunda etapa se mantendrá el esquema de la primera, además de incluir un obstáculo en la pista de pruebas, el que el robot tendrá que evadir.\\

Por cada una de las etapas se comprobará, de dos formas distintas, si la red neuronal está aprendiendo por medio del método de entrenamiento backpropagation, la primera es evaluando el aprendizaje con un set de datos distinto al del entrenamiento, aquí se evalúa cuanto difiere la salida esperada con la que entrega la red. Esta diferencia se considera “test error” (error de prueba) y esta será obtenida por la técnica de “Validation Set Approach” (enfoque de conjunto de validación) la que consiste en dejar parte del conjunto de entrenamiento para validar cuan efectivo fue este.\\

[completar cuantos datos de entrenamiento fueron y cuantos se dejaron para validation set approach]
la implementación de la red reordena de forma aleatoria el conjunto de datos y desde este crea un conjunto de datos para las pruebas
La cuantificación del error se realiza midiendo el porcentaje de efectividad de la red, contando la cantidad de veces que la salida de la red es una respuesta esperada, para saber si la salida satisface esta condición se establece un margen de aceptación de [porcentaje de aceptación], para qué se considere un entrenamiento efectivo la eficacia de la red debe estar sobre un [porcentaje de efectividad]\\ 

La segunda comprobación de entrenamiento se realizará de forma empírica, comparando el comportamiento de la conducción manual del robot, contra la conducción autónoma guiada por la red neuronal, cada vez que el robot se desplace por la pista de pruebas se deja registro de su desplazamiento, por lo que se puede comparar el recorrido realizado de forma manual y el de forma autónoma. Para considerar la prueba exitosa la desviación de las dos trayectorias no debe ser mayor a [medida de desviación].\\

La obtención del conjunto datos, para realizar las pruebas, consta de conducir de forma manual el robot repetidas veces por la pista de pruebas, colocando el robot en posiciones definidas al comienzo de la pista y dirigirlo hasta el final de esta.\\

Para la primera etapa, sin importar la posición de inicio, tiene como objetivo mover el robot al centro de la pista direccionándolo solo de forma horizontal [mejorar descripción del movimiento de robot, para que de esta forma la red neuronal pueda aprender a direccionar el robot evadiendo los bordes de la pista.\\

En la segunda etapa se posicionará un obstáculo dentro de la pista, al igual que en la primera etapa, también se deberá centrar el robot dentro de la pista, pero al enfrentarse a un obstáculo este debe ser evadido.\\

Para realizar la recopilación de datos, el inicio de la pista será dividido en [n] secciones iguales la que estarán divididas en [cm] una de otra, de donde comenzara el robot, por cada una de estas secciones se registrarán [n] recorridos del robot sobre la pista, obteniendo la información de flujo óptico y el recorrido echo por este. El recorrido registrado será a una velocidad constante [velocidad del robot] y recorrerá una distancia de [distancia a recorrer].\\

Para la recopilación de datos con obstáculos, se utilizará el mismo esquema anterior, pero se posicionará un obstáculo dentro de pista en distintas posiciones predefinas, estas posiciones son representadas dentro de la pista por una matriz, la cual será de [n] filas y [m] columnas, la separación entre las filas y las columnas será igual y de [cm], y estará posicionada en la pista a [distancia] del inicio de la pista y centrada con respecto a los bordes. Por cada obstáculo se recopilarán los datos [n] veces por cada posición de inicio de la pista.\\

La construcción de la pista de pruebas necesita de un material que proporcione tracción a las ruedas del robot, por lo que se decidió utilizar una alfombra de cubre pisos de 1 metro de ancho y 4 metros de largo, de color beige para proporcionar mayor contraste frente a los obstáculos, los bordes de la pista tendrán un alto de [cm] con un patrón regular líneas verticales blancas y negras de [cm] de ancho.

\chapter{Resultados}




%% ambiente glosario
\begin{glosario}
  \item[El primer término:] Este es el significado del primer término, realmente no se bien lo que significa pero podría haberlo averiguado si hubiese tenido un poco mas de tiempo.
  \item[El segundo término:] Este si se lo que significa pero me da lata escribirlo...
\end{glosario}


%% genera las referencias
\bibliography{refs}


%% comienzo de la parte de anexos
\appendixpart

%% contenido del primer anexo
\appendix{El Primer Anexo}
Aquí va el texto del primer anexo...

\section{La primera sección del primer anexo}
Aquí va el texto de la primera sección del primer anexo...

\section{La segunda sección del primer anexo}
Aquí va el texto de la segunda sección del primer anexo...

\subsection{La primera subsección de la segunda sección del primer anexo}


%% contenido del segundo anexo
\appendix{El segundo Anexo}
Aquí va el texto del segundo anexo...

\section{La primera sección del segundo anexo}
Aquí va el texto de la primera sección del segundo anexo...

%% fin
\end{document}

   

